{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying other models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already we have our cleaned training data and cleaned test data so in this notebook we will just focus to imporve our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Kolkata_Average_Price</th>\n",
       "      <th>Kolkata_Ref_Price</th>\n",
       "      <th>Bangalore_Average_Price</th>\n",
       "      <th>Bangalore_Ref_Price</th>\n",
       "      <th>Cochin_Average_Price</th>\n",
       "      <th>Cochin_Ref_Price</th>\n",
       "      <th>Darjeeling_Average_Price</th>\n",
       "      <th>Darjeeling_Ref_Price</th>\n",
       "      <th>Ernakulam_Average_Price</th>\n",
       "      <th>Ernakulam_Ref_Price</th>\n",
       "      <th>Siliguri_Average_Price</th>\n",
       "      <th>Siliguri_Ref_Price</th>\n",
       "      <th>Guwahati_Average_Price</th>\n",
       "      <th>Guwahati_Ref_Price</th>\n",
       "      <th>Average</th>\n",
       "      <th>SaleDate</th>\n",
       "      <th>SaleMonth</th>\n",
       "      <th>SaleYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>120.93</td>\n",
       "      <td>97.27</td>\n",
       "      <td>112.08</td>\n",
       "      <td>92.36</td>\n",
       "      <td>105.19</td>\n",
       "      <td>87.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.88</td>\n",
       "      <td>69.64</td>\n",
       "      <td>67.21</td>\n",
       "      <td>76.80</td>\n",
       "      <td>68.90</td>\n",
       "      <td>71.04</td>\n",
       "      <td>65.90</td>\n",
       "      <td>85.217692</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>95.95</td>\n",
       "      <td>71.01</td>\n",
       "      <td>87.66</td>\n",
       "      <td>71.01</td>\n",
       "      <td>80.58</td>\n",
       "      <td>67.16</td>\n",
       "      <td>82.25</td>\n",
       "      <td>57.49</td>\n",
       "      <td>69.64</td>\n",
       "      <td>52.48</td>\n",
       "      <td>71.66</td>\n",
       "      <td>53.18</td>\n",
       "      <td>69.51</td>\n",
       "      <td>48.04</td>\n",
       "      <td>69.830000</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>94.14</td>\n",
       "      <td>73.38</td>\n",
       "      <td>85.69</td>\n",
       "      <td>65.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.57</td>\n",
       "      <td>80.87</td>\n",
       "      <td>54.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.43</td>\n",
       "      <td>71.12</td>\n",
       "      <td>52.07</td>\n",
       "      <td>69.14</td>\n",
       "      <td>48.50</td>\n",
       "      <td>67.846667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>91.45</td>\n",
       "      <td>70.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.99</td>\n",
       "      <td>79.27</td>\n",
       "      <td>62.09</td>\n",
       "      <td>80.76</td>\n",
       "      <td>57.06</td>\n",
       "      <td>69.65</td>\n",
       "      <td>53.38</td>\n",
       "      <td>72.30</td>\n",
       "      <td>52.50</td>\n",
       "      <td>69.39</td>\n",
       "      <td>50.33</td>\n",
       "      <td>67.196923</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>126.49</td>\n",
       "      <td>95.14</td>\n",
       "      <td>122.25</td>\n",
       "      <td>87.51</td>\n",
       "      <td>118.95</td>\n",
       "      <td>86.36</td>\n",
       "      <td>87.37</td>\n",
       "      <td>59.05</td>\n",
       "      <td>85.14</td>\n",
       "      <td>56.17</td>\n",
       "      <td>83.31</td>\n",
       "      <td>55.35</td>\n",
       "      <td>79.73</td>\n",
       "      <td>53.50</td>\n",
       "      <td>85.451429</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Kolkata_Average_Price  Kolkata_Ref_Price  \\\n",
       "0          30                 120.93              97.27   \n",
       "1           2                  95.95              71.01   \n",
       "2           3                  94.14              73.38   \n",
       "3           4                  91.45              70.39   \n",
       "4          17                 126.49              95.14   \n",
       "\n",
       "   Bangalore_Average_Price  Bangalore_Ref_Price  Cochin_Average_Price  \\\n",
       "0                   112.08                92.36                105.19   \n",
       "1                    87.66                71.01                 80.58   \n",
       "2                    85.69                65.66                  0.00   \n",
       "3                     0.00                64.99                 79.27   \n",
       "4                   122.25                87.51                118.95   \n",
       "\n",
       "   Cochin_Ref_Price  Darjeeling_Average_Price  Darjeeling_Ref_Price  \\\n",
       "0             87.63                      0.00                 72.88   \n",
       "1             67.16                     82.25                 57.49   \n",
       "2             65.57                     80.87                 54.59   \n",
       "3             62.09                     80.76                 57.06   \n",
       "4             86.36                     87.37                 59.05   \n",
       "\n",
       "   Ernakulam_Average_Price  Ernakulam_Ref_Price  Siliguri_Average_Price  \\\n",
       "0                    69.64                67.21                   76.80   \n",
       "1                    69.64                52.48                   71.66   \n",
       "2                     0.00                53.43                   71.12   \n",
       "3                    69.65                53.38                   72.30   \n",
       "4                    85.14                56.17                   83.31   \n",
       "\n",
       "   Siliguri_Ref_Price  Guwahati_Average_Price  Guwahati_Ref_Price    Average  \\\n",
       "0               68.90                   71.04               65.90  85.217692   \n",
       "1               53.18                   69.51               48.04  69.830000   \n",
       "2               52.07                   69.14               48.50  67.846667   \n",
       "3               52.50                   69.39               50.33  67.196923   \n",
       "4               55.35                   79.73               53.50  85.451429   \n",
       "\n",
       "   SaleDate  SaleMonth  SaleYear  \n",
       "0         8          1      2009  \n",
       "1        17          1      2009  \n",
       "2        24          1      2009  \n",
       "3        31          1      2009  \n",
       "4         5          2      2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('cleaned_train.csv',index_col=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kolkata_Average_Price</th>\n",
       "      <th>Kolkata_Ref_Price</th>\n",
       "      <th>Bangalore_Average_Price</th>\n",
       "      <th>Bangalore_Ref_Price</th>\n",
       "      <th>Cochin_Average_Price</th>\n",
       "      <th>Cochin_Ref_Price</th>\n",
       "      <th>Darjeeling_Average_Price</th>\n",
       "      <th>Darjeeling_Ref_Price</th>\n",
       "      <th>Ernakulam_Average_Price</th>\n",
       "      <th>Ernakulam_Ref_Price</th>\n",
       "      <th>Siliguri_Average_Price</th>\n",
       "      <th>Siliguri_Ref_Price</th>\n",
       "      <th>Guwahati_Average_Price</th>\n",
       "      <th>Guwahati_Ref_Price</th>\n",
       "      <th>Average</th>\n",
       "      <th>SaleDate</th>\n",
       "      <th>SaleMonth</th>\n",
       "      <th>SaleYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.93</td>\n",
       "      <td>97.27</td>\n",
       "      <td>112.08</td>\n",
       "      <td>92.36</td>\n",
       "      <td>105.19</td>\n",
       "      <td>87.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.88</td>\n",
       "      <td>69.64</td>\n",
       "      <td>67.21</td>\n",
       "      <td>76.80</td>\n",
       "      <td>68.90</td>\n",
       "      <td>71.04</td>\n",
       "      <td>65.90</td>\n",
       "      <td>85.217692</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.95</td>\n",
       "      <td>71.01</td>\n",
       "      <td>87.66</td>\n",
       "      <td>71.01</td>\n",
       "      <td>80.58</td>\n",
       "      <td>67.16</td>\n",
       "      <td>82.25</td>\n",
       "      <td>57.49</td>\n",
       "      <td>69.64</td>\n",
       "      <td>52.48</td>\n",
       "      <td>71.66</td>\n",
       "      <td>53.18</td>\n",
       "      <td>69.51</td>\n",
       "      <td>48.04</td>\n",
       "      <td>69.830000</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.14</td>\n",
       "      <td>73.38</td>\n",
       "      <td>85.69</td>\n",
       "      <td>65.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.57</td>\n",
       "      <td>80.87</td>\n",
       "      <td>54.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.43</td>\n",
       "      <td>71.12</td>\n",
       "      <td>52.07</td>\n",
       "      <td>69.14</td>\n",
       "      <td>48.50</td>\n",
       "      <td>67.846667</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.45</td>\n",
       "      <td>70.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>64.99</td>\n",
       "      <td>79.27</td>\n",
       "      <td>62.09</td>\n",
       "      <td>80.76</td>\n",
       "      <td>57.06</td>\n",
       "      <td>69.65</td>\n",
       "      <td>53.38</td>\n",
       "      <td>72.30</td>\n",
       "      <td>52.50</td>\n",
       "      <td>69.39</td>\n",
       "      <td>50.33</td>\n",
       "      <td>67.196923</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126.49</td>\n",
       "      <td>95.14</td>\n",
       "      <td>122.25</td>\n",
       "      <td>87.51</td>\n",
       "      <td>118.95</td>\n",
       "      <td>86.36</td>\n",
       "      <td>87.37</td>\n",
       "      <td>59.05</td>\n",
       "      <td>85.14</td>\n",
       "      <td>56.17</td>\n",
       "      <td>83.31</td>\n",
       "      <td>55.35</td>\n",
       "      <td>79.73</td>\n",
       "      <td>53.50</td>\n",
       "      <td>85.451429</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Kolkata_Average_Price  Kolkata_Ref_Price  Bangalore_Average_Price  \\\n",
       "0                 120.93              97.27                   112.08   \n",
       "1                  95.95              71.01                    87.66   \n",
       "2                  94.14              73.38                    85.69   \n",
       "3                  91.45              70.39                     0.00   \n",
       "4                 126.49              95.14                   122.25   \n",
       "\n",
       "   Bangalore_Ref_Price  Cochin_Average_Price  Cochin_Ref_Price  \\\n",
       "0                92.36                105.19             87.63   \n",
       "1                71.01                 80.58             67.16   \n",
       "2                65.66                  0.00             65.57   \n",
       "3                64.99                 79.27             62.09   \n",
       "4                87.51                118.95             86.36   \n",
       "\n",
       "   Darjeeling_Average_Price  Darjeeling_Ref_Price  Ernakulam_Average_Price  \\\n",
       "0                      0.00                 72.88                    69.64   \n",
       "1                     82.25                 57.49                    69.64   \n",
       "2                     80.87                 54.59                     0.00   \n",
       "3                     80.76                 57.06                    69.65   \n",
       "4                     87.37                 59.05                    85.14   \n",
       "\n",
       "   Ernakulam_Ref_Price  Siliguri_Average_Price  Siliguri_Ref_Price  \\\n",
       "0                67.21                   76.80               68.90   \n",
       "1                52.48                   71.66               53.18   \n",
       "2                53.43                   71.12               52.07   \n",
       "3                53.38                   72.30               52.50   \n",
       "4                56.17                   83.31               55.35   \n",
       "\n",
       "   Guwahati_Average_Price  Guwahati_Ref_Price    Average  SaleDate  SaleMonth  \\\n",
       "0                   71.04               65.90  85.217692         8          1   \n",
       "1                   69.51               48.04  69.830000        17          1   \n",
       "2                   69.14               48.50  67.846667        24          1   \n",
       "3                   69.39               50.33  67.196923        31          1   \n",
       "4                   79.73               53.50  85.451429         5          2   \n",
       "\n",
       "   SaleYear  \n",
       "0      2009  \n",
       "1      2009  \n",
       "2      2009  \n",
       "3      2009  \n",
       "4      2009  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 544 entries, 0 to 543\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Kolkata_Average_Price     544 non-null    float64\n",
      " 1   Kolkata_Ref_Price         544 non-null    float64\n",
      " 2   Bangalore_Average_Price   544 non-null    float64\n",
      " 3   Bangalore_Ref_Price       544 non-null    float64\n",
      " 4   Cochin_Average_Price      544 non-null    float64\n",
      " 5   Cochin_Ref_Price          544 non-null    float64\n",
      " 6   Darjeeling_Average_Price  544 non-null    float64\n",
      " 7   Darjeeling_Ref_Price      544 non-null    float64\n",
      " 8   Ernakulam_Average_Price   544 non-null    float64\n",
      " 9   Ernakulam_Ref_Price       544 non-null    float64\n",
      " 10  Siliguri_Average_Price    544 non-null    float64\n",
      " 11  Siliguri_Ref_Price        544 non-null    float64\n",
      " 12  Guwahati_Average_Price    544 non-null    float64\n",
      " 13  Guwahati_Ref_Price        544 non-null    float64\n",
      " 14  Average                   544 non-null    float64\n",
      " 15  SaleDate                  544 non-null    int64  \n",
      " 16  SaleMonth                 544 non-null    int64  \n",
      " 17  SaleYear                  544 non-null    int64  \n",
      "dtypes: float64(15), int64(3)\n",
      "memory usage: 76.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kolkata_Average_Price       0\n",
       "Kolkata_Ref_Price           0\n",
       "Bangalore_Average_Price     0\n",
       "Bangalore_Ref_Price         0\n",
       "Cochin_Average_Price        0\n",
       "Cochin_Ref_Price            0\n",
       "Darjeeling_Average_Price    0\n",
       "Darjeeling_Ref_Price        0\n",
       "Ernakulam_Average_Price     0\n",
       "Ernakulam_Ref_Price         0\n",
       "Siliguri_Average_Price      0\n",
       "Siliguri_Ref_Price          0\n",
       "Guwahati_Average_Price      0\n",
       "Guwahati_Ref_Price          0\n",
       "Average                     0\n",
       "SaleDate                    0\n",
       "SaleMonth                   0\n",
       "SaleYear                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 42, 502, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Spliiting X and y\n",
    "np.random.seed(42)\n",
    "\n",
    "X = data.drop('Average',axis=1)\n",
    "y = data['Average']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=42)\n",
    "\n",
    "len(X_train), len(X_val), len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso' : Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'linear svr': SVR(kernel='linear'),\n",
    "    'rbf svr':SVR(),\n",
    "    'SGD': SGDRegressor(),\n",
    "    'Gradient':GradientBoostingRegressor(),\n",
    "    'Ada': AdaBoostRegressor(),\n",
    "    'Bagging': BaggingRegressor(),\n",
    "    'Kneighbor':KNeighborsRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE metric\n",
    "def rmse(y_true,y_preds):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(model,X_train,X_valid,y_train,y_valid):\n",
    "    for label,model in models.items():\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        #fitting the model\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        #predicting on validation \n",
    "        prediction_valid = model.predict(X_val)\n",
    "        \n",
    "        #MAE on validation set\n",
    "        MAE_valid = mean_absolute_error(y_valid,prediction_valid)\n",
    "        print(f'MAE_valid:{model} = {MAE_valid}')\n",
    "        \n",
    "        #RMSE on validation set\n",
    "        RMSE_valid = rmse(y_valid,prediction_valid)\n",
    "        print(f'RMSE_valid:{model} = {RMSE_valid}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE_valid:Ridge() = 3.9586695496060478\n",
      "RMSE_valid:Ridge() = 5.269597885821289\n",
      "MAE_valid:Lasso() = 3.7749062350200666\n",
      "RMSE_valid:Lasso() = 5.22126241766144\n",
      "MAE_valid:ElasticNet() = 3.7605382554738207\n",
      "RMSE_valid:ElasticNet() = 5.2708849158891935\n",
      "MAE_valid:SVR(kernel='linear') = 3.977902610137642\n",
      "RMSE_valid:SVR(kernel='linear') = 5.808381697462686\n",
      "MAE_valid:SVR() = 11.961593174517573\n",
      "RMSE_valid:SVR() = 14.506794890004166\n",
      "MAE_valid:SGDRegressor() = 3222891132077099.5\n",
      "RMSE_valid:SGDRegressor() = 3226544700977289.0\n",
      "MAE_valid:GradientBoostingRegressor() = 1.6328488951392155\n",
      "RMSE_valid:GradientBoostingRegressor() = 3.2575735695089256\n",
      "MAE_valid:AdaBoostRegressor() = 3.626379653250769\n",
      "RMSE_valid:AdaBoostRegressor() = 5.591907634382114\n",
      "MAE_valid:BaggingRegressor() = 1.9149766020000005\n",
      "RMSE_valid:BaggingRegressor() = 3.835969092507393\n",
      "MAE_valid:KNeighborsRegressor() = 4.030546905523808\n",
      "RMSE_valid:KNeighborsRegressor() = 7.31205360751375\n"
     ]
    }
   ],
   "source": [
    "fit_score(\n",
    "    model = models,\n",
    "    X_train = X_train,\n",
    "    X_valid = X_val,\n",
    "    y_train = y_train,\n",
    "    y_valid = y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see GradientBoostingRegressor and Bagging quiter perform well on default parameters so let's hypertune our these two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's tune our model by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators is 10 and score is 3.835969092507393\n",
      "Number of estimators is 20 and score is 3.6983317661376116\n",
      "Number of estimators is 30 and score is 3.588823136574166\n",
      "Number of estimators is 40 and score is 3.7253650609547497\n",
      "Number of estimators is 50 and score is 3.49085921031683\n",
      "Number of estimators is 60 and score is 3.5201917161536933\n",
      "Number of estimators is 70 and score is 3.6408884706790072\n",
      "Number of estimators is 80 and score is 3.6636580551073203\n",
      "Number of estimators is 90 and score is 3.694645183857085\n",
      "Number of estimators is 100 and score is 3.6992817472462756\n"
     ]
    }
   ],
   "source": [
    "#for bagging regressor\n",
    "n_estimators = [10,20,30,40,50,60,70,80,90,100]\n",
    "np.random.seed(42)\n",
    "for i in n_estimators:\n",
    "    bagging_model = BaggingRegressor(n_estimators=i)\n",
    "    bagging_model.fit(X_train,y_train)\n",
    "    bagging_preds = bagging_model.predict(X_val)\n",
    "    bagging_score = rmse(y_val,bagging_preds)\n",
    "    print(f'Number of estimators is {i} and score is {bagging_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our **bagging_model** perform good on **n_estiamtors = 60** compare to b aseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators is 100 and score is 3.2575735695089256\n",
      "Number of estimators is 190 and score is 3.212696559753233\n",
      "Number of estimators is 200 and score is 3.294720356622678\n",
      "Number of estimators is 210 and score is 3.2927086166958435\n",
      "Number of estimators is 900 and score is 3.235873702416429\n",
      "Number of estimators is 1000 and score is 3.1980825012559158\n",
      "Number of estimators is 1100 and score is 3.237915860032344\n"
     ]
    }
   ],
   "source": [
    "#for Gradient Boosting regressor\n",
    "n_estimators_gradient = [100,190,200,210,900,1000,1100]\n",
    "np.random.seed(42)\n",
    "for i in n_estimators_gradient:\n",
    "    gradient_model = GradientBoostingRegressor(n_estimators=i)\n",
    "    gradient_model.fit(X_train,y_train)\n",
    "    gradient_preds = gradient_model.predict(X_val)\n",
    "    gradient_score = rmse(y_val,gradient_preds)\n",
    "    print(f'Number of estimators is {i} and score is {gradient_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to bagging model our **gradient booting** model perform well when **number of estimator is 1000**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit our gradient boosting with these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = GradientBoostingRegressor(n_estimators=1000,random_state=42)\n",
    "model_1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_preds = model_1.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.223349233002795"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_rmse = rmse(y_val,model_1_preds)\n",
    "model_1_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('cleaned_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kolkata_Average_Price</th>\n",
       "      <th>Kolkata_Ref_Price</th>\n",
       "      <th>Bangalore_Average_Price</th>\n",
       "      <th>Bangalore_Ref_Price</th>\n",
       "      <th>Cochin_Average_Price</th>\n",
       "      <th>Cochin_Ref_Price</th>\n",
       "      <th>Darjeeling_Average_Price</th>\n",
       "      <th>Darjeeling_Ref_Price</th>\n",
       "      <th>Ernakulam_Average_Price</th>\n",
       "      <th>Ernakulam_Ref_Price</th>\n",
       "      <th>Siliguri_Average_Price</th>\n",
       "      <th>Siliguri_Ref_Price</th>\n",
       "      <th>Guwahati_Average_Price</th>\n",
       "      <th>Guwahati_Ref_Price</th>\n",
       "      <th>SaleDate</th>\n",
       "      <th>SaleMonth</th>\n",
       "      <th>SaleYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.35</td>\n",
       "      <td>165.87</td>\n",
       "      <td>154.080</td>\n",
       "      <td>160.82</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>116.45</td>\n",
       "      <td>112.82</td>\n",
       "      <td>91.82</td>\n",
       "      <td>93.90</td>\n",
       "      <td>102.30</td>\n",
       "      <td>105.66</td>\n",
       "      <td>83.07</td>\n",
       "      <td>65.34</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171.35</td>\n",
       "      <td>173.12</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>90.68</td>\n",
       "      <td>76.34</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>81.34</td>\n",
       "      <td>83.32</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>156.140</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>150.39</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>96.84</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>158.040</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>146.68</td>\n",
       "      <td>111.24</td>\n",
       "      <td>111.47</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>97.87</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>157.550</td>\n",
       "      <td>163.85</td>\n",
       "      <td>132.70</td>\n",
       "      <td>144.87</td>\n",
       "      <td>112.49</td>\n",
       "      <td>111.44</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>179.47</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>107.52</td>\n",
       "      <td>111.32</td>\n",
       "      <td>77.77</td>\n",
       "      <td>80.61</td>\n",
       "      <td>89.80</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>163.940</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>81.98</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>182.14</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>83.83</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>183.59</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>160.61</td>\n",
       "      <td>138.75</td>\n",
       "      <td>139.98</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>171.35</td>\n",
       "      <td>169.98</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>121.85</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>98.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>174.81</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>81.91</td>\n",
       "      <td>93.90</td>\n",
       "      <td>91.21</td>\n",
       "      <td>101.24</td>\n",
       "      <td>68.30</td>\n",
       "      <td>83.32</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>68.20</td>\n",
       "      <td>81.55</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>171.35</td>\n",
       "      <td>161.30</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>140.40</td>\n",
       "      <td>108.07</td>\n",
       "      <td>134.41</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>82.68</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>149.500</td>\n",
       "      <td>150.93</td>\n",
       "      <td>132.25</td>\n",
       "      <td>142.63</td>\n",
       "      <td>108.69</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>89.83</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>85.06</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>112.81</td>\n",
       "      <td>71.73</td>\n",
       "      <td>84.91</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>162.83</td>\n",
       "      <td>160.65</td>\n",
       "      <td>154.080</td>\n",
       "      <td>147.19</td>\n",
       "      <td>129.09</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>132.55</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>171.35</td>\n",
       "      <td>160.79</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>130.74</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>73.13</td>\n",
       "      <td>83.32</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>171.35</td>\n",
       "      <td>164.21</td>\n",
       "      <td>151.215</td>\n",
       "      <td>148.63</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>108.65</td>\n",
       "      <td>73.55</td>\n",
       "      <td>83.32</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>136.59</td>\n",
       "      <td>141.61</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.05</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>108.00</td>\n",
       "      <td>72.72</td>\n",
       "      <td>79.19</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>113.03</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>96.51</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>155.60</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.30</td>\n",
       "      <td>138.11</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>95.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.72</td>\n",
       "      <td>85.73</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>78.12</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>141.720</td>\n",
       "      <td>147.28</td>\n",
       "      <td>137.61</td>\n",
       "      <td>146.67</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>125.19</td>\n",
       "      <td>77.62</td>\n",
       "      <td>102.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>94.29</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>171.35</td>\n",
       "      <td>159.12</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>92.62</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>92.22</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>153.19</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>140.67</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>115.97</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>97.73</td>\n",
       "      <td>94.82</td>\n",
       "      <td>111.75</td>\n",
       "      <td>66.11</td>\n",
       "      <td>83.32</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>171.35</td>\n",
       "      <td>162.13</td>\n",
       "      <td>154.080</td>\n",
       "      <td>149.95</td>\n",
       "      <td>132.70</td>\n",
       "      <td>142.63</td>\n",
       "      <td>112.49</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>96.61</td>\n",
       "      <td>94.82</td>\n",
       "      <td>105.66</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>152.94</td>\n",
       "      <td>162.13</td>\n",
       "      <td>134.250</td>\n",
       "      <td>149.95</td>\n",
       "      <td>135.65</td>\n",
       "      <td>142.63</td>\n",
       "      <td>116.47</td>\n",
       "      <td>120.89</td>\n",
       "      <td>79.64</td>\n",
       "      <td>93.90</td>\n",
       "      <td>94.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72.72</td>\n",
       "      <td>83.32</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kolkata_Average_Price  Kolkata_Ref_Price  Bangalore_Average_Price  \\\n",
       "0                  171.35             165.87                  154.080   \n",
       "1                  171.35             173.12                  154.080   \n",
       "2                  171.35             162.13                  156.140   \n",
       "3                  171.35             162.13                  158.040   \n",
       "4                  171.35             162.13                  157.550   \n",
       "5                  179.47             162.13                  154.080   \n",
       "6                  171.35             162.13                  163.940   \n",
       "7                  182.14             162.13                  154.080   \n",
       "8                  183.59             162.13                  154.080   \n",
       "9                  171.35             169.98                  154.080   \n",
       "10                 174.81             162.13                  154.080   \n",
       "11                 171.35             162.13                  154.080   \n",
       "12                 171.35             161.30                  154.080   \n",
       "13                 171.35             162.13                  149.500   \n",
       "14                 171.35             162.13                  154.080   \n",
       "15                 162.83             160.65                  154.080   \n",
       "16                 171.35             160.79                  154.080   \n",
       "17                 171.35             164.21                  151.215   \n",
       "18                 171.35             162.13                  154.080   \n",
       "19                 171.35             162.13                  154.080   \n",
       "20                 171.35             162.13                  154.080   \n",
       "21                 155.60             162.13                  154.080   \n",
       "22                 171.35             162.13                  154.080   \n",
       "23                 171.35             162.13                  141.720   \n",
       "24                 171.35             162.13                  154.080   \n",
       "25                 171.35             159.12                  154.080   \n",
       "26                 153.19             162.13                  154.080   \n",
       "27                 171.35             162.13                  154.080   \n",
       "28                 152.94             162.13                  134.250   \n",
       "\n",
       "    Bangalore_Ref_Price  Cochin_Average_Price  Cochin_Ref_Price  \\\n",
       "0                160.82                132.70            142.63   \n",
       "1                149.95                132.70            142.63   \n",
       "2                149.95                132.70            150.39   \n",
       "3                149.95                132.70            146.68   \n",
       "4                163.85                132.70            144.87   \n",
       "5                149.95                132.70            142.63   \n",
       "6                149.95                132.70            142.63   \n",
       "7                149.95                132.70            142.63   \n",
       "8                160.61                138.75            139.98   \n",
       "9                149.95                132.70            142.63   \n",
       "10               149.95                132.70            142.63   \n",
       "11               149.95                132.70            142.63   \n",
       "12               149.95                132.70            140.40   \n",
       "13               150.93                132.25            142.63   \n",
       "14               149.95                132.70            142.63   \n",
       "15               147.19                129.09            142.63   \n",
       "16               149.95                130.74            142.63   \n",
       "17               148.63                132.70            142.63   \n",
       "18               149.95                132.70            142.63   \n",
       "19               149.95                136.59            141.61   \n",
       "20               149.95                132.70            142.63   \n",
       "21               149.95                132.30            138.11   \n",
       "22               149.95                132.70            142.63   \n",
       "23               147.28                137.61            146.67   \n",
       "24               149.95                132.70            142.63   \n",
       "25               149.95                132.70            142.63   \n",
       "26               140.67                132.70            142.63   \n",
       "27               149.95                132.70            142.63   \n",
       "28               149.95                135.65            142.63   \n",
       "\n",
       "    Darjeeling_Average_Price  Darjeeling_Ref_Price  Ernakulam_Average_Price  \\\n",
       "0                     116.45                112.82                    91.82   \n",
       "1                     112.49                120.89                    90.68   \n",
       "2                     112.49                120.89                    79.64   \n",
       "3                     111.24                111.47                    79.64   \n",
       "4                     112.49                111.44                    79.64   \n",
       "5                     107.52                111.32                    77.77   \n",
       "6                     112.49                120.89                    79.64   \n",
       "7                     112.49                120.89                    79.64   \n",
       "8                     112.49                120.89                    79.64   \n",
       "9                     112.49                121.85                    79.64   \n",
       "10                    112.49                120.89                    81.91   \n",
       "11                    112.49                120.89                    79.64   \n",
       "12                    108.07                134.41                    79.64   \n",
       "13                    108.69                120.89                    79.64   \n",
       "14                    112.49                120.89                    85.06   \n",
       "15                    112.49                132.55                    79.64   \n",
       "16                    112.49                120.89                    79.64   \n",
       "17                    112.49                120.89                    79.64   \n",
       "18                    112.49                120.89                    79.64   \n",
       "19                    112.49                120.89                    79.05   \n",
       "20                    113.03                120.89                    79.64   \n",
       "21                    112.49                120.89                    79.64   \n",
       "22                    112.49                120.89                    78.12   \n",
       "23                    112.49                120.89                    79.64   \n",
       "24                    112.49                125.19                    77.62   \n",
       "25                    112.49                120.89                    79.64   \n",
       "26                    115.97                120.89                    79.64   \n",
       "27                    112.49                120.89                    79.64   \n",
       "28                    116.47                120.89                    79.64   \n",
       "\n",
       "    Ernakulam_Ref_Price  Siliguri_Average_Price  Siliguri_Ref_Price  \\\n",
       "0                 93.90                  102.30              105.66   \n",
       "1                 76.34                   94.82              105.66   \n",
       "2                 93.90                   96.84              105.66   \n",
       "3                 93.90                   97.87              105.66   \n",
       "4                 93.90                   94.82              105.66   \n",
       "5                 80.61                   89.80              105.66   \n",
       "6                 81.98                   94.82              105.66   \n",
       "7                 83.83                   94.82              105.66   \n",
       "8                 93.90                   94.82              105.66   \n",
       "9                 93.90                   94.82               98.66   \n",
       "10                93.90                   91.21              101.24   \n",
       "11                93.90                   94.82              105.66   \n",
       "12                93.90                   94.82              105.66   \n",
       "13                93.90                   89.83              105.66   \n",
       "14                93.90                   94.82              112.81   \n",
       "15                93.90                   94.82              105.66   \n",
       "16                93.90                   94.82              105.66   \n",
       "17                93.90                   94.82              108.65   \n",
       "18                93.90                   94.82              105.66   \n",
       "19                93.90                   94.82              108.00   \n",
       "20                96.51                   94.82              105.66   \n",
       "21                93.90                   95.10                0.00   \n",
       "22                93.90                   94.82              105.66   \n",
       "23                93.90                   94.82              105.66   \n",
       "24               102.90                   94.82              105.66   \n",
       "25                93.90                   92.62              105.66   \n",
       "26                97.73                   94.82              111.75   \n",
       "27                96.61                   94.82              105.66   \n",
       "28                93.90                   94.82                0.00   \n",
       "\n",
       "    Guwahati_Average_Price  Guwahati_Ref_Price  SaleDate  SaleMonth  SaleYear  \n",
       "0                    83.07               65.34        15          6      2019  \n",
       "1                    81.34               83.32        22          6      2019  \n",
       "2                    72.72               83.32        29          6      2019  \n",
       "3                    72.72               83.32         7          6      2019  \n",
       "4                    72.72               83.32        13          7      2019  \n",
       "5                    72.72               83.32        20          7      2019  \n",
       "6                    72.72               83.32        27          7      2019  \n",
       "7                    72.72               83.32         8          3      2019  \n",
       "8                    72.72               83.32         8         10      2019  \n",
       "9                    72.72               83.32        17          8      2019  \n",
       "10                   68.30               83.32        24          8      2019  \n",
       "11                   68.20               81.55        31          8      2019  \n",
       "12                   72.72               82.68         9          7      2019  \n",
       "13                   72.72               83.32        14          9      2019  \n",
       "14                   71.73               84.91        21          9      2019  \n",
       "15                   72.72               83.32        28          9      2019  \n",
       "16                   73.13               83.32        10          5      2019  \n",
       "17                   73.55               83.32        10         12      2019  \n",
       "18                   72.72               83.32        19         10      2019  \n",
       "19                   72.72               79.19        26         10      2019  \n",
       "20                   72.72               83.32        11          2      2019  \n",
       "21                   72.72               85.73        11          9      2019  \n",
       "22                   72.72               83.32        16         11      2019  \n",
       "23                   72.72               83.32        23         11      2019  \n",
       "24                   72.72               94.29        30         11      2019  \n",
       "25                   72.72               92.22        12          7      2019  \n",
       "26                   66.11               83.32        14         12      2019  \n",
       "27                   72.72               83.32        21         12      2019  \n",
       "28                   72.72               83.32        28         12      2019  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model_1.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame()\n",
    "submission_df['Average'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('my_second_submission_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning our Gradient Boosting Regressor Model (Experimenting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we going to make our **n_estimators = 1000** and further experimenting with other parameters **by hand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate is 0.01 and score is 3.302683280318492\n",
      "Learning rate is 0.1 and score is 3.208013872335586\n",
      "Learning rate is 1 and score is 5.941931646537374\n"
     ]
    }
   ],
   "source": [
    "#hypertuning learning_rate\n",
    "learning_rate = [0.01,0.1,1]\n",
    "np.random.seed(42)\n",
    "for i in learning_rate:\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=1000,learning_rate=i)\n",
    "    gb_model.fit(X_train,y_train)\n",
    "    gb_preds = gb_model.predict(X_val)\n",
    "    gb_score = rmse(y_val,gb_preds)\n",
    "    print(f'Learning rate is {i} and score is {gb_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous hypertuned model got **3.223** **RMSE** and this new hypertuned model got around **3.20 RMSE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's further experimenting with our model with this parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's fit our model with n_estimators = 1000 and learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth is 2 and score is 2.668125277956219\n",
      "Max depth is 3 and score is 3.259394321632904\n",
      "Max depth is 4 and score is 3.627449229359672\n",
      "Max depth is 5 and score is 3.765008213639044\n",
      "Max depth is 6 and score is 3.723372439604142\n",
      "Max depth is 7 and score is 3.864597483181562\n",
      "Max depth is 8 and score is 4.030259003613861\n"
     ]
    }
   ],
   "source": [
    "#hypertuning max_depth\n",
    "max_depth = [2,3,4,5,6,7,8]\n",
    "np.random.seed(35)\n",
    "for i in max_depth:\n",
    "    gbm_model = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=i)\n",
    "    gbm_model.fit(X_train,y_train)\n",
    "    gbm_preds = gbm_model.predict(X_val)\n",
    "    gbm_score = rmse(y_val,gbm_preds)\n",
    "    print(f'Max depth is {i} and score is {gbm_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah that's pretty score jumping from **3.20** to **2.66** with **max_depth = 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's fit our model with these parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.668125277956219"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(35)\n",
    "model_2 = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2)\n",
    "model_2.fit(X_train,y_train)\n",
    "preds_2 = model_2.predict(X_val)\n",
    "rmse_2 = rmse(y_val,preds_2)\n",
    "rmse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Test Predictions with this new hypertuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_2 = model_2.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_2 = pd.DataFrame()\n",
    "submission_df_2['Average'] = test_preds_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.650813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.596354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.787465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.440412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.181463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>116.253570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>118.132431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>118.951551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>121.138722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>119.691814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>118.574552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>118.584194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>120.589456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>116.929737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119.662014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>118.311419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>118.407216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>118.836698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>119.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>119.335444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>119.809804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>117.197959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>119.459662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>119.515891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>121.255701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>119.447630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>117.240679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>119.645454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>117.472369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average\n",
       "0   119.650813\n",
       "1   117.596354\n",
       "2   119.787465\n",
       "3   119.440412\n",
       "4   119.181463\n",
       "5   116.253570\n",
       "6   118.132431\n",
       "7   118.951551\n",
       "8   121.138722\n",
       "9   119.691814\n",
       "10  118.574552\n",
       "11  118.584194\n",
       "12  120.589456\n",
       "13  116.929737\n",
       "14  119.662014\n",
       "15  118.311419\n",
       "16  118.407216\n",
       "17  118.836698\n",
       "18  119.520500\n",
       "19  119.335444\n",
       "20  119.809804\n",
       "21  117.197959\n",
       "22  119.459662\n",
       "23  119.515891\n",
       "24  121.255701\n",
       "25  119.447630\n",
       "26  117.240679\n",
       "27  119.645454\n",
       "28  117.472369"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('my_third_submission_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Experimneting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is ls and score is 2.668125277956219\n",
      "Loss is lad and score is 3.082174406739605\n",
      "Loss is huber and score is 2.9721927633941716\n"
     ]
    }
   ],
   "source": [
    "loss = ['ls','lad','huber']\n",
    "\n",
    "np.random.seed(35)\n",
    "for i in loss:\n",
    "    gbml_model = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,loss=i)\n",
    "    gbml_model.fit(X_train,y_train)\n",
    "    gbml_preds = gbml_model.predict(X_val)\n",
    "    gbml_score = rmse(y_val,gbml_preds)\n",
    "    print(f'Loss is {i} and score is {gbml_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split is 2 and score is 2.668125277956219\n",
      "min_samples_split is 3 and score is 2.6789303055672367\n",
      "min_samples_split is 4 and score is 2.677370718906436\n",
      "min_samples_split is 5 and score is 2.6754255686531176\n",
      "min_samples_split is 6 and score is 2.6896556048200995\n",
      "min_samples_split is 7 and score is 2.6901343854515303\n",
      "min_samples_split is 8 and score is 2.61298079738006\n"
     ]
    }
   ],
   "source": [
    "min_samples_split = [2,3,4,5,6,7,8]\n",
    "np.random.seed(35)\n",
    "for i in min_samples_split:\n",
    "    gbmls_model = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,loss='ls',min_samples_split=i)\n",
    "    gbmls_model.fit(X_train,y_train)\n",
    "    gbmls_preds = gbmls_model.predict(X_val)\n",
    "    gbmls_score = rmse(y_val,gbmls_preds)\n",
    "    print(f'min_samples_split is {i} and score is {gbmls_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take **min_samples_split = 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf is 2 and score is 2.626050909393405\n",
      "min_samples_leaf is 3 and score is 2.5918886508509584\n",
      "min_samples_leaf is 4 and score is 2.6635635017805583\n",
      "min_samples_leaf is 5 and score is 2.575415321606267\n",
      "min_samples_leaf is 6 and score is 2.608473562071202\n",
      "min_samples_leaf is 7 and score is 2.5946151002503117\n",
      "min_samples_leaf is 8 and score is 2.726797399842577\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf = [2,3,4,5,6,7,8]\n",
    "np.random.seed(35)\n",
    "for i in min_samples_leaf:\n",
    "    gbmlsl_model = GradientBoostingRegressor(n_estimators=1000,learning_rate=0.1,max_depth=2,loss='ls',min_samples_split=8,min_samples_leaf=i)\n",
    "    gbmlsl_model.fit(X_train,y_train)\n",
    "    gbmlsl_preds = gbmlsl_model.predict(X_val)\n",
    "    gbmlsl_score = rmse(y_val,gbmlsl_preds)\n",
    "    print(f'min_samples_leaf is {i} and score is {gbmlsl_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max feature is auto and score is 2.5754817045683276\n",
      "max feature is sqrt and score is 2.643352312245121\n",
      "max feature is log2 and score is 2.8207821659451295\n"
     ]
    }
   ],
   "source": [
    "max_features = ['auto', 'sqrt','log2']\n",
    "np.random.seed(35)\n",
    "for i in max_features:\n",
    "    gbmlslm_model = GradientBoostingRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=2,\n",
    "        loss='ls',\n",
    "        min_samples_split=8,\n",
    "        min_samples_leaf=5,\n",
    "        max_features=i\n",
    "    )\n",
    "    gbmlslm_model.fit(X_train,y_train)\n",
    "    gbmlslm_preds = gbmlslm_model.predict(X_val)\n",
    "    gbmlslm_score = rmse(y_val,gbmlslm_preds)\n",
    "    print(f'max feature is {i} and score is {gbmlslm_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning our hypermeters by hand, let's fit our model with our best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, max_features='auto', min_samples_leaf=5,\n",
       "                          min_samples_split=8, n_estimators=1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = GradientBoostingRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=2,\n",
    "        loss='ls',\n",
    "        min_samples_split=8,\n",
    "        min_samples_leaf=5,\n",
    "        max_features='auto'\n",
    "    )\n",
    "\n",
    "final_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = final_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse = rmse(y_val,final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.575415321606267"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_preds = final_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119.73947829, 117.48573241, 119.44402655, 119.11080552,\n",
       "       119.2731768 , 116.0457075 , 118.1247529 , 118.87627044,\n",
       "       120.96804104, 119.41442413, 117.98776839, 118.88548031,\n",
       "       120.5458375 , 116.4826444 , 119.54856164, 118.70464909,\n",
       "       118.53552358, 119.10974376, 119.54042385, 119.26480449,\n",
       "       119.77451119, 117.1101971 , 119.53167251, 119.61042501,\n",
       "       121.35620577, 119.1177061 , 117.38206105, 119.69593011,\n",
       "       117.77813124])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission['Average'] = final_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.739478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.485732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.444027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.110806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119.273177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Average\n",
       "0  119.739478\n",
       "1  117.485732\n",
       "2  119.444027\n",
       "3  119.110806\n",
       "4  119.273177"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv('my_fourth_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
